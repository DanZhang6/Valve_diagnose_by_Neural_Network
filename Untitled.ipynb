{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tf_utils1 import load_dataset1, random_mini_batches, convert_to_one_hot, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_X, Train_Y, Dev_X, Dev_Y, Test_X, Test_Y, X_Anomaly=load_dataset1();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Computes the sigmoid of z\n",
    "    \n",
    "    Arguments:\n",
    "    z -- input value, scalar or vector\n",
    "    \n",
    "    Returns: \n",
    "    results -- the sigmoid of z\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### ( approx. 4 lines of code)\n",
    "    # Create a placeholder for x. Name it 'x'.\n",
    "    x = tf.placeholder(tf.float32, name=\"x\")\n",
    "\n",
    "    # compute sigmoid(x)\n",
    "    sigmoid = tf.sigmoid(x)\n",
    "\n",
    "    # Create a session, and run it. Please use the method 2 explained above. \n",
    "    # You should use a feed_dict to pass z's value to x. \n",
    "    with tf.Session() as sess: \n",
    "    # run the variables initialization (if needed), run the operations\n",
    "        # Run session and call the output \"result\"\n",
    "        result = sess.run(sigmoid, feed_dict = {x: z})\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1. \n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- vector containing the labels \n",
    "    C -- number of classes, the depth of the one hot dimension\n",
    "    \n",
    "    Returns: \n",
    "    one_hot -- one hot matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)\n",
    "    #C = tf.constant(C, name = \"C\")\n",
    "    depth = tf.constant(value = C, name = 'C')\n",
    "    \n",
    "    # Use tf.one_hot, be careful with the axis (approx. 1 line)\n",
    "    #one_hot_matrix = tf.one_hot(labels, C, axis = 0)\n",
    "    one_hot_matrix = tf.one_hot(labels, depth, axis = 0)\n",
    "    \n",
    "    # Create the session (approx. 1 line)\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Run the session (approx. 1 line)\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 16880\n",
      "number of test examples = 5629\n",
      "X_train shape: (280, 16880)\n",
      "Y_train shape: (5, 16880, 1)\n",
      "X_test shape: (280, 5629)\n",
      "Y_test shape: (5, 5629, 1)\n"
     ]
    }
   ],
   "source": [
    "Y_train_orig=np.matrix(Train_Y[1,:])\n",
    "Y_test_orig=np.matrix(Dev_Y[1,:])\n",
    "X_train=Train_X\n",
    "X_test=Dev_X\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6)\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6)\n",
    "Y_train=np.delete(Y_train, 0, 0)\n",
    "Y_test=np.delete(Y_test, 0, 0)\n",
    "print (\"number of training examples = \" + str(X_train.shape[1]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[1]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    #X = tf.placeholder(tf.float32, shape = (n_x, None), name = \"X\")\n",
    "    #Y = tf.placeholder(tf.float32, shape = (n_y, None), name = \"Y\")\n",
    "    X = tf.placeholder(tf.float32, shape=[n_x, None])\n",
    "    Y = tf.placeholder(tf.float32, shape=[n_y, None])\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [25, 12288]\n",
    "                        b1 : [25, 1]\n",
    "                        W2 : [12, 25]\n",
    "                        b2 : [12, 1]\n",
    "                        W3 : [6, 12]\n",
    "                        b3 : [6, 1]\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [100,280], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    b1 = tf.get_variable(\"b1\", [100,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [50,100], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    b2 = tf.get_variable(\"b2\", [50,1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [50,50], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    b3 = tf.get_variable(\"b3\", [50,1], initializer = tf.zeros_initializer())\n",
    "    W4 = tf.get_variable(\"W4\", [25,50], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    b4 = tf.get_variable(\"b4\", [25,1], initializer = tf.zeros_initializer())\n",
    "    W5 = tf.get_variable(\"W5\", [12,25], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    b5 = tf.get_variable(\"b5\", [12,1], initializer = tf.zeros_initializer())\n",
    "    W6 = tf.get_variable(\"W6\", [5,12], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    b6 = tf.get_variable(\"b6\", [5,1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3,\n",
    "                  \"W4\": W4,\n",
    "                  \"b4\": b4,\n",
    "                  \"W5\": W5,\n",
    "                  \"b5\": b5,\n",
    "                  \"W6\": W6,\n",
    "                  \"b6\": b6,}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    W4 = parameters['W4']\n",
    "    b4 = parameters['b4']\n",
    "    W5 = parameters['W5']\n",
    "    b5 = parameters['b5']\n",
    "    W6 = parameters['W6']\n",
    "    b6 = parameters['b6']\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)                        # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                       # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)                       # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                       # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)                       # Z3 = np.dot(W3,Z2) + b3\n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    Z4 = tf.add(tf.matmul(W4,A3),b4)                       # Z3 = np.dot(W3,Z2) + b3\n",
    "    A4 = tf.nn.relu(Z4)\n",
    "    Z5 = tf.add(tf.matmul(W5,A4),b5)                       # Z3 = np.dot(W3,Z2) + b3\n",
    "    A5 = tf.nn.relu(Z5)\n",
    "    Z6 = tf.add(tf.matmul(W6,A5),b6)                       # Z3 = np.dot(W3,Z2) + b3\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return Z6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z6, Y, parameters):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    lambd=0.1\n",
    "    m = Y.shape[1]\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "    W4 = parameters['W4']\n",
    "    W5 = parameters['W5']\n",
    "    W6 = parameters['W6']\n",
    "    \n",
    "    tf.add_to_collection(tf.GraphKeys.WEIGHTS, W1)\n",
    "    tf.add_to_collection(tf.GraphKeys.WEIGHTS, W2)\n",
    "    tf.add_to_collection(tf.GraphKeys.WEIGHTS, W3)\n",
    "    tf.add_to_collection(tf.GraphKeys.WEIGHTS, W4)\n",
    "    tf.add_to_collection(tf.GraphKeys.WEIGHTS, W5)\n",
    "    tf.add_to_collection(tf.GraphKeys.WEIGHTS, W6)\n",
    "\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(scale=0.002)\n",
    "\n",
    "    reg_term = tf.contrib.layers.apply_regularization(regularizer)\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z6)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    #cost = tf.nn.softmax_cross_entropy_with_logits (labels = labels, logits = logits)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))+reg_term\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0004,\n",
    "          num_epochs = 1600, minibatch_size = 64, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    #tf.set_random_seed(1)                             # to keep consistent results\n",
    "    #seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z6 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z6, Y, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z6), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: np.matrix(Y_train)}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: np.matrix(Y_test)}))\n",
    "        \n",
    "        return parameters,Z6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.255207\n",
      "Cost after epoch 100: 0.465383\n",
      "Cost after epoch 200: 0.398712\n",
      "Cost after epoch 300: 0.372453\n",
      "Cost after epoch 400: 0.360557\n",
      "Cost after epoch 500: 0.345465\n",
      "Cost after epoch 600: 0.353794\n",
      "Cost after epoch 700: 0.328351\n",
      "Cost after epoch 800: 0.354540\n",
      "Cost after epoch 900: 0.324812\n",
      "Cost after epoch 1000: 0.317119\n",
      "Cost after epoch 1100: 0.314479\n",
      "Cost after epoch 1200: 0.319583\n",
      "Cost after epoch 1300: 0.307989\n",
      "Cost after epoch 1400: 0.307102\n",
      "Cost after epoch 1500: 0.300433\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12398b080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.933057\n",
      "Test Accuracy: 0.922011\n"
     ]
    }
   ],
   "source": [
    "parameters,Z6 = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensorboard' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-f9cb64cd6d5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tensorboard' is not defined"
     ]
    }
   ],
   "source": [
    "tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-f63cdbadb177>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorrect_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Train Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhangdan/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     \"\"\"\n\u001b[0;32m--> 541\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhangdan/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   4069\u001b[0m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4070\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4071\u001b[0;31m       raise ValueError(\"Cannot evaluate tensor using `eval()`: No default \"\n\u001b[0m\u001b[1;32m   4072\u001b[0m                        \u001b[0;34m\"session is registered. Use `with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4073\u001b[0m                        \u001b[0;34m\"sess.as_default()` or pass an explicit session to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`"
     ]
    }
   ],
   "source": [
    "(n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "n_y = Y_train.shape[0] \n",
    "X, Y = create_placeholders(n_x, n_y)\n",
    "correct_prediction = tf.equal(tf.argmax(Z6), tf.argmax(Y))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z6' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-dc5507282cde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorrect_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Train Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'z6' is not defined"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(z6), tf.argmax(Y))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "dataFile = '/Users/zhangdan/Documents/GitHub/Volve-Fault-Detection/DNN_NEW/saveddata.mat'\n",
    "data = scio.loadmat(dataFile)\n",
    "Y_test=data['Y_test']\n",
    "Y_train=data['Y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Anomaly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file='/Users/zhangdan/Documents/GitHub/Volve-Fault-Detection/DNN_NEW/Anomaly.mat'\n",
    "data=scio.loadmat(file)\n",
    "Anomaly=data['Anomaly']\n",
    "Anomaly_Y=data['Anomaly_Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result=np.ones((1,n))\n",
    "for i in range(n):\n",
    "    result[0,i]=predict(Anomaly[:,i].reshape((1, 280)).T, parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[m,n]=Anomaly.shape\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "\n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    "\n",
    "    params = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3}\n",
    "\n",
    "    x = tf.placeholder(\"float\", [280, 1])\n",
    "\n",
    "    z3 = forward_propagation_for_predict(x, params)\n",
    "    p = tf.argmax(z3)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    prediction = sess.run(p, feed_dict = {x: X})\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "\n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    "    W4 = tf.convert_to_tensor(parameters[\"W4\"])\n",
    "    b4 = tf.convert_to_tensor(parameters[\"b4\"])\n",
    "    W5 = tf.convert_to_tensor(parameters[\"W5\"])\n",
    "    b5 = tf.convert_to_tensor(parameters[\"b5\"])\n",
    "    W6 = tf.convert_to_tensor(parameters[\"W6\"])\n",
    "    b6 = tf.convert_to_tensor(parameters[\"b6\"])\n",
    "\n",
    "    params = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3,\n",
    "              \"W4\": W4,\n",
    "              \"b4\": b4,\n",
    "              \"W5\": W5,\n",
    "              \"b5\": b5,\n",
    "              \"W6\": W6,\n",
    "              \"b6\": b6}\n",
    "\n",
    "    x = tf.placeholder(\"float\", [280, 1])\n",
    "\n",
    "    z6 = forward_propagation_for_predict(x, params)\n",
    "    p = tf.argmax(z6)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    prediction = sess.run(p, feed_dict = {x: X})\n",
    "\n",
    "    return prediction\n",
    "\n",
    "def forward_propagation_for_predict(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "\n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve the parameters from the dictionary \"parameters\"\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    W4 = parameters['W4']\n",
    "    b4 = parameters['b4']\n",
    "    W5 = parameters['W5']\n",
    "    b5 = parameters['b5']\n",
    "    W6 = parameters['W6']\n",
    "    b6 = parameters['b6']\n",
    "                                                           # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n",
    "    A3 = tf.nn.relu(Z3)                                    # A2 = relu(Z2)\n",
    "    Z4 = tf.add(tf.matmul(W4, A3), b4)\n",
    "    A4 = tf.nn.relu(Z4)                                    # A2 = relu(Z2)\n",
    "    Z5 = tf.add(tf.matmul(W5, A4), b5)\n",
    "    A5 = tf.nn.relu(Z5)                                    # A2 = relu(Z2)\n",
    "    Z6 = tf.add(tf.matmul(W6, A5), b6)\n",
    "\n",
    "    return Z6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "## START CODE HERE ## (PUT YOUR IMAGE NAME) \n",
    "my_image = \"thumbs_up.jpg\"\n",
    "## END CODE HERE ##\n",
    "\n",
    "# We preprocess your image to fit your algorithm.\n",
    "fname = \"images/\" + my_image\n",
    "image = np.array(ndimage.imread(fname, flatten=False))\n",
    "my_image = scipy.misc.imresize(image, size=(64,64)).reshape((1, 64*64*3)).T\n",
    "my_image_prediction = predict(my_image, parameters)\n",
    "\n",
    "plt.imshow(image)\n",
    "print(\"Your algorithm predicts: y = \" + str(np.squeeze(my_image_prediction)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
